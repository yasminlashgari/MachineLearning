{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import statsmodels.api as sm\n",
    "from astropy.table import QTable, Table, Column\n",
    "from astropy import units as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "df_monthly = pd.read_excel('PredictorData2019.xlsx',sheet_name=\"Monthly\")\n",
    "# Parse the dates properly\n",
    "time = [str(d) for d in df_monthly.yyyymm]\n",
    "df_monthly.index = pd.to_datetime(time,format=\"%Y%m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable construction\n",
    "df_monthly['ExRet'] = df_monthly['CRSP_SPvw']-df_monthly['Rfree']\n",
    "df_monthly['DP'] = np.log(df_monthly['D12'])-np.log(df_monthly['Index'])\n",
    "df_monthly['DY'] = np.log(df_monthly['D12'])-np.log(df_monthly['Index'].shift())\n",
    "df_monthly['EP'] = np.log(df_monthly['E12'])-np.log(df_monthly['Index'])\n",
    "df_monthly['DE'] = np.log(df_monthly['D12'])-np.log(df_monthly['E12'])\n",
    "df_monthly['tms'] = df_monthly['lty']-df_monthly['tbl']\n",
    "df_monthly['dfr'] = df_monthly['corpr']-df_monthly['ltr']\n",
    "df_monthly['dfy'] = df_monthly['BAA']-df_monthly['AAA']\n",
    "\n",
    "\n",
    "# infl needs to be lagged one more month\n",
    "df_monthly['infl'] = df_monthly['infl'].shift().copy()\n",
    "\n",
    "# Construction of dependent and independent variables\n",
    "dep_var = 'ExRet'\n",
    "indep_vars = ['DE','svar','dfr','lty','ltr','infl','tms','tbl','dfy','DP','DY','EP','b/m','ntis']\n",
    "\n",
    "# Use the data from 1926/12 to 2019/12\n",
    "subperiod = df_monthly.index>='1926-12-01'\n",
    "df = df_monthly[subperiod]\n",
    "M = 240 # Initial length of estimation window\n",
    "gam = 3 # risk aversion coefficient\n",
    "\n",
    "# Create the benchmark using historical average\n",
    "Hist_Mean = np.asarray(df[dep_var].expanding().mean().shift())\n",
    "Hist_Variance = np.asarray(df[dep_var].expanding().var().shift())\n",
    "\n",
    "# Benchmark SSE (Historical Average)\n",
    "OOS_SSE_Hist = np.sum((df[dep_var][M+1:]-Hist_Mean[M+1:])**2)\n",
    "\n",
    "# Benchmark Certainty Equivalence\n",
    "w0 = ((1/gam)*(Hist_Mean/Hist_Variance)).clip(None,1.5);\n",
    "r0 = df[dep_var]*w0\n",
    "CE_Hist = np.mean(r0[M+1:])-gam/2*np.var(r0[M+1:],ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following codes demonstrate how to compute OOS $R^2$ and CEV for one predictive regression (using DY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.asarray(df[dep_var])\n",
    "X = np.asarray(df['DY'])\n",
    "Y_Hat = np.full(len(Y), np.nan)\n",
    "X = sm.add_constant(X)\n",
    "# Note that we start the index at M+1 because the first element of predicted return is at t=M+2.\n",
    "for i in range(M+1,len(Y)):\n",
    "    Y1 = Y[1:i]\n",
    "    X1 = X[0:i-1,:] \n",
    "    reg = sm.OLS(Y1, X1, missing='drop').fit()\n",
    "    Y_Hat[i] = reg.predict(X[i-1,:]) \n",
    "\n",
    "    # The predicted value is based on the observation before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "OOS_SSE = np.sum((Y[M+1:]-Y_Hat[M+1:])**2)\n",
    "OOS_R2 = 1-OOS_SSE/OOS_SSE_Hist\n",
    "w1 = ((1/gam)*(Y_Hat/Hist_Variance)).clip(None,1.5);\n",
    "r1 = Y*w1\n",
    "CE = np.mean(r1[M+1:])-gam/2*np.var(r1[M+1:],ddof=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-sample $R^2$ and out-of-sample $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IS R^2 =  0.435\n",
      "OOS R^2 = -0.920\n"
     ]
    }
   ],
   "source": [
    "reg1 = sm.OLS(Y[1:],X[0:len(Y)-1,:],missing='drop').fit()\n",
    "IS_R2 = reg1.rsquared\n",
    "print(\"IS R^2 = %6.3f\"%(100.0*IS_R2))\n",
    "print(\"OOS R^2 = %6.3f\"%(100.0*OOS_R2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\Delta CEV$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in Certainty Equivalence = -0.1489\n"
     ]
    }
   ],
   "source": [
    "print('Difference in Certainty Equivalence = %7.4f'%(100*(CE-CE_Hist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for finding the three main deliverables\n",
    "def r2(var):\n",
    "    Y = np.asarray(df[dep_var])\n",
    "    X = np.asarray(df[var])\n",
    "    Y_Hat = np.full(len(Y), np.nan)\n",
    "    X = sm.add_constant(X)\n",
    "    for i in range(M+1,len(Y)):\n",
    "        Y1 = Y[1:i]\n",
    "        X1 = X[0:i-1,:] \n",
    "        reg = sm.OLS(Y1, X1, missing='drop').fit()\n",
    "        Y_Hat[i] = reg.predict(X[i-1,:])       # The predicted value is based on the observation before\n",
    "    OOS_SSE = np.sum((Y[M+1:]-Y_Hat[M+1:])**2)\n",
    "    OOS_R2 = 1-OOS_SSE/OOS_SSE_Hist\n",
    "    w1 = ((1/gam)*(Y_Hat/Hist_Variance)).clip(None,1.5);\n",
    "    r1 = Y*w1\n",
    "    CE = np.mean(r1[M+1:])-gam/2*np.var(r1[M+1:],ddof=1)\n",
    "    reg1 = sm.OLS(Y[1:],X[0:len(Y)-1,:],missing='drop').fit()\n",
    "    IS_R2 = reg1.rsquared\n",
    "    return((100.0*IS_R2))\n",
    "\n",
    "def oos(var):\n",
    "    Y = np.asarray(df[dep_var])\n",
    "    X = np.asarray(df[var])\n",
    "    Y_Hat = np.full(len(Y), np.nan)\n",
    "    X = sm.add_constant(X)\n",
    "    for i in range(M+1,len(Y)):\n",
    "        Y1 = Y[1:i]\n",
    "        X1 = X[0:i-1,:] \n",
    "        reg = sm.OLS(Y1, X1, missing='drop').fit()\n",
    "        Y_Hat[i] = reg.predict(X[i-1,:])       # The predicted value is based on the observation before\n",
    "    OOS_SSE = np.sum((Y[M+1:]-Y_Hat[M+1:])**2)\n",
    "    OOS_R2 = 1-OOS_SSE/OOS_SSE_Hist\n",
    "    w1 = ((1/gam)*(Y_Hat/Hist_Variance)).clip(None,1.5);\n",
    "    r1 = Y*w1\n",
    "    CE = np.mean(r1[M+1:])-gam/2*np.var(r1[M+1:],ddof=1)\n",
    "    reg1 = sm.OLS(Y[1:],X[0:len(Y)-1,:],missing='drop').fit()\n",
    "    IS_R2 = reg1.rsquared\n",
    "    return ((100.0*OOS_R2))\n",
    "\n",
    "def cev(var):\n",
    "    Y = np.asarray(df[dep_var])\n",
    "    X = np.asarray(df[var])\n",
    "    Y_Hat = np.full(len(Y), np.nan)\n",
    "    X = sm.add_constant(X)\n",
    "    for i in range(M+1,len(Y)):\n",
    "        Y1 = Y[1:i]\n",
    "        X1 = X[0:i-1,:] \n",
    "        reg = sm.OLS(Y1, X1, missing='drop').fit()\n",
    "        Y_Hat[i] = reg.predict(X[i-1,:])       # The predicted value is based on the observation before\n",
    "    OOS_SSE = np.sum((Y[M+1:]-Y_Hat[M+1:])**2)\n",
    "    OOS_R2 = 1-OOS_SSE/OOS_SSE_Hist\n",
    "    w1 = ((1/gam)*(Y_Hat/Hist_Variance)).clip(None,1.5);\n",
    "    r1 = Y*w1\n",
    "    CE = np.mean(r1[M+1:])-gam/2*np.var(r1[M+1:],ddof=1)\n",
    "    reg1 = sm.OLS(Y[1:],X[0:len(Y)-1,:],missing='drop').fit()\n",
    "    IS_R2 = reg1.rsquared\n",
    "    return ((100*(CE-CE_Hist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable In Sample R^2 Out of sample R^2     CEV     \n",
      "-------- ------------- ----------------- ------------\n",
      "      DE  0.0006394605        -0.7178052  0.003935941\n",
      "    svar   0.009658814        -0.5716513  -0.04712237\n",
      "     dfr   0.114465244       -0.20323741  0.001140755\n",
      "     lty     0.1896013       -0.32233942  -0.07532967\n",
      "     ltr     0.2963518        -0.1928927   0.02597267\n",
      "    infl    0.13845016         -0.035171 -0.011508059\n",
      "     tms    0.15968142       0.119112745    0.0493356\n",
      "     tbl    0.31838322        0.24510683 -0.013011963\n",
      "     dfy    0.24592756       -0.35886228 -0.061638128\n",
      "      DP    0.32735413       -0.27166054   -0.1182665\n",
      "      DY    0.43484208       -0.92020184   -0.1488644\n",
      "      EP    0.38387606        -1.5207888 -0.089466274\n",
      "     b/m    0.63807136        -2.3932865  -0.21761905\n",
      "    ntis     0.4635411        -0.8107004  0.046325497\n"
     ]
    }
   ],
   "source": [
    "t = Table()\n",
    "\n",
    "t = Table(names=(\"Variable\",'In Sample R^2', 'Out of sample R^2', 'CEV'), dtype=(\"S2\",'f4','f4','f4'))\n",
    "#t.add_row((r2(\"svar\"), oos(\"svar\"), cev(\"svar\")))\n",
    "\n",
    "for variable in indep_vars:\n",
    "    t.add_row((variable, r2(variable), oos(variable), cev(variable)))\n",
    "    \n",
    "print(t)\n",
    "\n",
    "#Q1- finding report from predictive regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The in sample r^2 are all all close to 0 and positive\n",
    "#Out of sample r^2 is negative and have large numbers\n",
    "#this demonstrates the data is not linear and has a lot of outliers\n",
    "#CEV: predicts risk tolreance- these low numbers indicate low appetite for risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kitchen sink regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for finding the three main deliverables\n",
    "def r21(varlist):\n",
    "    Y = np.asarray(df[dep_var])\n",
    "    X = np.asarray(df[varlist])\n",
    "    Y_Hat = np.full(len(Y), np.nan)\n",
    "    X = sm.add_constant(X)\n",
    "    for i in range(M+1,len(Y)):\n",
    "        Y1 = Y[1:i]\n",
    "        X1 = X[0:i-1,:] \n",
    "        reg = sm.OLS(Y1, X1, missing='drop').fit()\n",
    "        Y_Hat[i] = reg.predict(X[i-1,:])       # The predicted value is based on the observation before\n",
    "    OOS_SSE = np.sum((Y[M+1:]-Y_Hat[M+1:])**2)\n",
    "    OOS_R2 = 1-OOS_SSE/OOS_SSE_Hist\n",
    "    w1 = ((1/gam)*(Y_Hat/Hist_Variance)).clip(None,1.5);\n",
    "    r1 = Y*w1\n",
    "    CE = np.mean(r1[M+1:])-gam/2*np.var(r1[M+1:],ddof=1)\n",
    "    reg1 = sm.OLS(Y[1:],X[0:len(Y)-1,:],missing='drop').fit()\n",
    "    IS_R2 = reg1.rsquared\n",
    "    return((100.0*IS_R2))\n",
    "\n",
    "def oos1(varlist):\n",
    "    Y = np.asarray(df[dep_var])\n",
    "    X = np.asarray(df[varlist])\n",
    "    Y_Hat = np.full(len(Y), np.nan)\n",
    "    X = sm.add_constant(X)\n",
    "    for i in range(M+1,len(Y)):\n",
    "        Y1 = Y[1:i]\n",
    "        X1 = X[0:i-1,:] \n",
    "        reg = sm.OLS(Y1, X1, missing='drop').fit()\n",
    "        Y_Hat[i] = reg.predict(X[i-1,:])       # The predicted value is based on the observation before\n",
    "    OOS_SSE = np.sum((Y[M+1:]-Y_Hat[M+1:])**2)\n",
    "    OOS_R2 = 1-OOS_SSE/OOS_SSE_Hist\n",
    "    w1 = ((1/gam)*(Y_Hat/Hist_Variance)).clip(None,1.5);\n",
    "    r1 = Y*w1\n",
    "    CE = np.mean(r1[M+1:])-gam/2*np.var(r1[M+1:],ddof=1)\n",
    "    reg1 = sm.OLS(Y[1:],X[0:len(Y)-1,:],missing='drop').fit()\n",
    "    IS_R2 = reg1.rsquared\n",
    "    return ((100.0*OOS_R2))\n",
    "\n",
    "def cev1(varlist):\n",
    "    Y = np.asarray(df[dep_var])\n",
    "    X = np.asarray(df[varlist])\n",
    "    Y_Hat = np.full(len(Y), np.nan)\n",
    "    X = sm.add_constant(X)\n",
    "    for i in range(M+1,len(Y)):\n",
    "        Y1 = Y[1:i]\n",
    "        X1 = X[0:i-1,:] \n",
    "        reg = sm.OLS(Y1, X1, missing='drop').fit()\n",
    "        Y_Hat[i] = reg.predict(X[i-1,:])       # The predicted value is based on the observation before\n",
    "    OOS_SSE = np.sum((Y[M+1:]-Y_Hat[M+1:])**2)\n",
    "    OOS_R2 = 1-OOS_SSE/OOS_SSE_Hist\n",
    "    w1 = ((1/gam)*(Y_Hat/Hist_Variance)).clip(None,1.5);\n",
    "    r1 = Y*w1\n",
    "    CE = np.mean(r1[M+1:])-gam/2*np.var(r1[M+1:],ddof=1)\n",
    "    reg1 = sm.OLS(Y[1:],X[0:len(Y)-1,:],missing='drop').fit()\n",
    "    IS_R2 = reg1.rsquared\n",
    "    return ((100*(CE-CE_Hist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  In Sample R^2     Out of sample R^2          CEV        \n",
      "------------------ ------------------- -------------------\n",
      "3.1219264453077655 -12.468861821616306 -0.4585651279479323\n"
     ]
    }
   ],
   "source": [
    "k_vars = ['svar','dfr','lty','ltr','infl','tbl','dfy','DP','DY','EP','b/m','ntis']\n",
    "\n",
    "kitchensink = Table()\n",
    "\n",
    "kitchensink = Table(names=('In Sample R^2', 'Out of sample R^2', 'CEV'))\n",
    "    \n",
    "kitchensink.add_row((r21(k_vars), oos1(k_vars), cev1(k_vars)))\n",
    " \n",
    "#result for kitchen sink regression\n",
    "print(kitchensink)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#running a multiple regression does not improve the linearity of the results\n",
    "#The in sample R^2 and out of sample R^2 become more extreme\n",
    "# it is better to predict results using simple regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 2- market risk premium non-negative\n",
    "\n",
    "#redefining functions under this new rule \n",
    "\n",
    "def oos2(var):\n",
    "    Y = np.asarray(df[dep_var])\n",
    "    X = np.asarray(df[var])\n",
    "    Y_Hat = np.full(len(Y), np.nan)\n",
    "    X = sm.add_constant(X)\n",
    "    for i in range(M+1,len(Y)):\n",
    "        Y1 = Y[1:i]\n",
    "        X1 = X[0:i-1,:] \n",
    "        reg = sm.OLS(Y1, X1, missing='drop').fit()\n",
    "        if reg.predict(X[i-1,:])<0:\n",
    "            Y_Hat[i]=0\n",
    "        else:\n",
    "            Y_Hat[i] = reg.predict(X[i-1,:])     #the change is made here- all negative values are now 0\n",
    "    OOS_SSE = np.sum((Y[M+1:]-Y_Hat[M+1:])**2)\n",
    "    OOS_R2 = 1-OOS_SSE/OOS_SSE_Hist\n",
    "    w1 = ((1/gam)*(Y_Hat/Hist_Variance)).clip(None,1.5);\n",
    "    r1 = Y*w1\n",
    "    CE = np.mean(r1[M+1:])-gam/2*np.var(r1[M+1:],ddof=1)\n",
    "    reg1 = sm.OLS(Y[1:],X[0:len(Y)-1,:],missing='drop').fit()\n",
    "    IS_R2 = reg1.rsquared\n",
    "    return ((100.0*OOS_R2))\n",
    "\n",
    "def cev2(var):\n",
    "    Y = np.asarray(df[dep_var])\n",
    "    X = np.asarray(df[var])\n",
    "    Y_Hat = np.full(len(Y), np.nan)\n",
    "    X = sm.add_constant(X)\n",
    "    for i in range(M+1,len(Y)):\n",
    "        Y1 = Y[1:i]\n",
    "        X1 = X[0:i-1,:] \n",
    "        reg = sm.OLS(Y1, X1, missing='drop').fit()\n",
    "        if reg.predict(X[i-1,:])<0:\n",
    "            Y_Hat[i]=0\n",
    "        else:\n",
    "            Y_Hat[i] = reg.predict(X[i-1,:]) \n",
    "    OOS_SSE = np.sum((Y[M+1:]-Y_Hat[M+1:])**2)\n",
    "    OOS_R2 = 1-OOS_SSE/OOS_SSE_Hist\n",
    "    w1 = ((1/gam)*(Y_Hat/Hist_Variance)).clip(None,1.5);\n",
    "    r1 = Y*w1\n",
    "    CE = np.mean(r1[M+1:])-gam/2*np.var(r1[M+1:],ddof=1)\n",
    "    reg1 = sm.OLS(Y[1:],X[0:len(Y)-1,:],missing='drop').fit()\n",
    "    IS_R2 = reg1.rsquared\n",
    "    return ((100*(CE-CE_Hist)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Out of sample R^2     CEV     \n",
      "-------- ----------------- ------------\n",
      "      DE       -0.69191146 0.0063462476\n",
      "    svar        -0.5716513  -0.04712237\n",
      "     dfr       -0.27880135 -0.004435554\n",
      "     lty        0.51333714 -0.013300285\n",
      "     ltr       -0.17034924  0.026736056\n",
      "    infl      -0.006068724  -0.00967761\n",
      "     tms        0.13921714    0.0496991\n",
      "     tbl         0.4560654 -0.002042573\n",
      "     dfy       -0.34492996 -0.061112046\n",
      "      DP        0.12286735  -0.08646371\n",
      "      DY       -0.09960274 -0.089261435\n",
      "      EP        -0.7773259  -0.01412735\n",
      "     b/m        -1.7703474   -0.1690757\n",
      "    ntis        -0.8107004  0.046325497\n"
     ]
    }
   ],
   "source": [
    "#single variable regression\n",
    "t1 = Table()\n",
    "\n",
    "t1 = Table(names=(\"Variable\", 'Out of sample R^2', 'CEV'), dtype=(\"S2\",'f4','f4'))\n",
    "\n",
    "for variable in indep_vars:\n",
    "    t1.add_row((variable, oos2(variable), cev2(variable)))\n",
    "    \n",
    "print(t1)\n",
    "\n",
    "#table that gives out of sample R^2 and CEV using only positive market risk premiums (Y^)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the market risk premium non-negative imrpoved linearity of results \n",
    "# This function is a better way of predicting expected returns- there are less outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multivariable regression\n",
    "\n",
    "#redefining functions \n",
    "\n",
    "def oos3(varlist):\n",
    "    Y = np.asarray(df[dep_var])\n",
    "    X = np.asarray(df[varlist])\n",
    "    Y_Hat = np.full(len(Y), np.nan)\n",
    "    X = sm.add_constant(X)\n",
    "    for i in range(M+1,len(Y)):\n",
    "        Y1 = Y[1:i]\n",
    "        X1 = X[0:i-1,:] \n",
    "        reg = sm.OLS(Y1, X1, missing='drop').fit()\n",
    "        if reg.predict(X[i-1,:])<0:\n",
    "            Y_Hat[i]=0\n",
    "        else:\n",
    "            Y_Hat[i] = reg.predict(X[i-1,:])     #the change is made here- all negative values are now 0\n",
    "    OOS_SSE = np.sum((Y[M+1:]-Y_Hat[M+1:])**2)\n",
    "    OOS_R2 = 1-OOS_SSE/OOS_SSE_Hist\n",
    "    w1 = ((1/gam)*(Y_Hat/Hist_Variance)).clip(None,1.5);\n",
    "    r1 = Y*w1\n",
    "    CE = np.mean(r1[M+1:])-gam/2*np.var(r1[M+1:],ddof=1)\n",
    "    reg1 = sm.OLS(Y[1:],X[0:len(Y)-1,:],missing='drop').fit()\n",
    "    IS_R2 = reg1.rsquared\n",
    "    return ((100.0*OOS_R2))\n",
    "\n",
    "def cev3(varlist):\n",
    "    Y = np.asarray(df[dep_var])\n",
    "    X = np.asarray(df[varlist])\n",
    "    Y_Hat = np.full(len(Y), np.nan)\n",
    "    X = sm.add_constant(X)\n",
    "    for i in range(M+1,len(Y)):\n",
    "        Y1 = Y[1:i]\n",
    "        X1 = X[0:i-1,:] \n",
    "        reg = sm.OLS(Y1, X1, missing='drop').fit()\n",
    "        if reg.predict(X[i-1,:])<0:\n",
    "            Y_Hat[i]=0\n",
    "        else:\n",
    "            Y_Hat[i] = reg.predict(X[i-1,:]) \n",
    "    OOS_SSE = np.sum((Y[M+1:]-Y_Hat[M+1:])**2)\n",
    "    OOS_R2 = 1-OOS_SSE/OOS_SSE_Hist\n",
    "    w1 = ((1/gam)*(Y_Hat/Hist_Variance)).clip(None,1.5);\n",
    "    r1 = Y*w1\n",
    "    CE = np.mean(r1[M+1:])-gam/2*np.var(r1[M+1:],ddof=1)\n",
    "    reg1 = sm.OLS(Y[1:],X[0:len(Y)-1,:],missing='drop').fit()\n",
    "    IS_R2 = reg1.rsquared\n",
    "    return ((100*(CE-CE_Hist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of sample R^2           CEV         \n",
      "------------------ ---------------------\n",
      "-6.803982814387743 -0.002086763174287973\n"
     ]
    }
   ],
   "source": [
    "k_vars = ['svar','dfr','lty','ltr','infl','tbl','dfy','DP','DY','EP','b/m','ntis']\n",
    "\n",
    "kitchensink = Table()\n",
    "\n",
    "kitchensink = Table(names=('Out of sample R^2', 'CEV'))\n",
    "    \n",
    "kitchensink.add_row((oos3(k_vars), cev3(k_vars)))\n",
    " \n",
    "#result for kitchen sink regression\n",
    "print(kitchensink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#while the out of sample R^2 is less extreme, it is still less accurate compared to the simple regression analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question 3- two combination forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-6282907997b0>:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"mean_var\"]= df1.mean(axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B/M</th>\n",
       "      <th>TBL</th>\n",
       "      <th>LTY</th>\n",
       "      <th>NTIS</th>\n",
       "      <th>INFL</th>\n",
       "      <th>LTR</th>\n",
       "      <th>SVAR</th>\n",
       "      <th>dy</th>\n",
       "      <th>dp</th>\n",
       "      <th>ep</th>\n",
       "      <th>de</th>\n",
       "      <th>TMS</th>\n",
       "      <th>DFR</th>\n",
       "      <th>DFY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1926-12-01</th>\n",
       "      <td>0.441476</td>\n",
       "      <td>0.0307</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>0.050885</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>-2.956570</td>\n",
       "      <td>-2.973012</td>\n",
       "      <td>-2.386837</td>\n",
       "      <td>-0.586175</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>-0.0022</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927-01-01</th>\n",
       "      <td>0.443706</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.050833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>-2.963349</td>\n",
       "      <td>-2.942374</td>\n",
       "      <td>-2.374773</td>\n",
       "      <td>-0.567601</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>0.0095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927-02-01</th>\n",
       "      <td>0.428501</td>\n",
       "      <td>0.0329</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.051681</td>\n",
       "      <td>-0.011299</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>-2.932946</td>\n",
       "      <td>-2.979535</td>\n",
       "      <td>-2.430353</td>\n",
       "      <td>-0.549182</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>0.0092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927-03-01</th>\n",
       "      <td>0.469765</td>\n",
       "      <td>0.0320</td>\n",
       "      <td>0.0331</td>\n",
       "      <td>0.046370</td>\n",
       "      <td>-0.005714</td>\n",
       "      <td>0.0253</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>-2.970053</td>\n",
       "      <td>-2.976535</td>\n",
       "      <td>-2.445079</td>\n",
       "      <td>-0.531456</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>-0.0170</td>\n",
       "      <td>0.0092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927-04-01</th>\n",
       "      <td>0.456754</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.050518</td>\n",
       "      <td>-0.005747</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>-2.967143</td>\n",
       "      <td>-2.984225</td>\n",
       "      <td>-2.471309</td>\n",
       "      <td>-0.512916</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01</th>\n",
       "      <td>0.237917</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>-0.010244</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>0.004318</td>\n",
       "      <td>-3.959588</td>\n",
       "      <td>-3.941330</td>\n",
       "      <td>-3.086025</td>\n",
       "      <td>-0.855305</td>\n",
       "      <td>-0.0032</td>\n",
       "      <td>-0.0059</td>\n",
       "      <td>0.0089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-01</th>\n",
       "      <td>0.233377</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>-0.010959</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.0192</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>-3.934654</td>\n",
       "      <td>-3.951689</td>\n",
       "      <td>-3.108987</td>\n",
       "      <td>-0.842702</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01</th>\n",
       "      <td>0.232261</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>-0.013267</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>-0.0052</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>-3.945758</td>\n",
       "      <td>-3.965984</td>\n",
       "      <td>-3.112869</td>\n",
       "      <td>-0.853115</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01</th>\n",
       "      <td>0.223938</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>-0.007907</td>\n",
       "      <td>0.002286</td>\n",
       "      <td>-0.0059</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>-3.960088</td>\n",
       "      <td>-3.993568</td>\n",
       "      <td>-3.130267</td>\n",
       "      <td>-0.863301</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01</th>\n",
       "      <td>0.220116</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>-0.007306</td>\n",
       "      <td>-0.000536</td>\n",
       "      <td>-0.0253</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>-3.987707</td>\n",
       "      <td>-4.015896</td>\n",
       "      <td>-3.142629</td>\n",
       "      <td>-0.873266</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1117 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 B/M     TBL     LTY      NTIS      INFL     LTR      SVAR  \\\n",
       "1926-12-01  0.441476  0.0307  0.0354  0.050885  0.005682  0.0078  0.000465   \n",
       "1927-01-01  0.443706  0.0323  0.0351  0.050833  0.000000  0.0075  0.000470   \n",
       "1927-02-01  0.428501  0.0329  0.0347  0.051681 -0.011299  0.0088  0.000287   \n",
       "1927-03-01  0.469765  0.0320  0.0331  0.046370 -0.005714  0.0253  0.000924   \n",
       "1927-04-01  0.456754  0.0339  0.0333  0.050518 -0.005747 -0.0005  0.000603   \n",
       "...              ...     ...     ...       ...       ...     ...       ...   \n",
       "2019-08-01  0.237917  0.0195  0.0163 -0.010244  0.001671  0.0797  0.004318   \n",
       "2019-09-01  0.233377  0.0189  0.0170 -0.010959 -0.000051 -0.0192  0.000605   \n",
       "2019-10-01  0.232261  0.0165  0.0171 -0.013267  0.000783 -0.0052  0.001510   \n",
       "2019-11-01  0.223938  0.0154  0.0181 -0.007907  0.002286 -0.0059  0.000306   \n",
       "2019-12-01  0.220116  0.0154  0.0186 -0.007306 -0.000536 -0.0253  0.000502   \n",
       "\n",
       "                  dy        dp        ep        de     TMS     DFR     DFY  \n",
       "1926-12-01 -2.956570 -2.973012 -2.386837 -0.586175  0.0047 -0.0022  0.0100  \n",
       "1927-01-01 -2.963349 -2.942374 -2.374773 -0.567601  0.0028 -0.0019  0.0095  \n",
       "1927-02-01 -2.932946 -2.979535 -2.430353 -0.549182  0.0018 -0.0019  0.0092  \n",
       "1927-03-01 -2.970053 -2.976535 -2.445079 -0.531456  0.0011 -0.0170  0.0092  \n",
       "1927-04-01 -2.967143 -2.984225 -2.471309 -0.512916 -0.0006  0.0060  0.0090  \n",
       "...              ...       ...       ...       ...     ...     ...     ...  \n",
       "2019-08-01 -3.959588 -3.941330 -3.086025 -0.855305 -0.0032 -0.0059  0.0089  \n",
       "2019-09-01 -3.934654 -3.951689 -3.108987 -0.842702 -0.0019  0.0002  0.0088  \n",
       "2019-10-01 -3.945758 -3.965984 -3.112869 -0.853115  0.0006  0.0058  0.0091  \n",
       "2019-11-01 -3.960088 -3.993568 -3.130267 -0.863301  0.0027  0.0073  0.0088  \n",
       "2019-12-01 -3.987707 -4.015896 -3.142629 -0.873266  0.0032  0.0164  0.0087  \n",
       "\n",
       "[1117 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the combination forcast using mean and median\n",
    "#reinitialzing a new database using the values from the old database\n",
    "df1= pd.DataFrame(columns=[\"B/M\", \"TBL\", \"LTY\", \"NTIS\", \"INFL\", \"LTR\", \"SVAR\", \"dy\", \"dp\", \"ep\", \"de\", \"TMS\", \"DFR\", \"DFY\"])\n",
    "df1[\"B/M\"]= df['b/m']\n",
    "df1[\"TBL\"]= df['tbl']\n",
    "df1[\"LTY\"]= df[\"lty\"]\n",
    "df1[\"NTIS\"]= df[\"ntis\"]\n",
    "df1[\"INFL\"]= df[\"infl\"]\n",
    "df1[\"LTR\"]= df[\"ltr\"]\n",
    "df1[\"SVAR\"]= df[\"svar\"]\n",
    "df1[\"dy\"]=df[\"DY\"]\n",
    "df1[\"dp\"]= df[\"DP\"]\n",
    "df1[\"ep\"]= df[\"EP\"]\n",
    "df1[\"de\"]= df[\"DE\"]\n",
    "df1[\"TMS\"]= df[\"tms\"]\n",
    "df1[\"DFR\"]= df[\"dfr\"]\n",
    "df1[\"DFY\"]= df[\"dfy\"]\n",
    "\n",
    "\n",
    "df[\"mean_var\"]= df1.mean(axis=1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOS R^2 = -0.942\n",
      "Difference in Certainty Equivalence = -0.1530\n"
     ]
    }
   ],
   "source": [
    "#finding out of sample r^2 and cev for mean \n",
    "\n",
    "Y= np.asarray(df[dep_var])\n",
    "X= np.asarray(df['mean_var'])\n",
    "Y_Hat= np.full(len(Y), np.nan)\n",
    "X= sm.add_constant(X)\n",
    "\n",
    "for a in range(M+1, len(Y)):\n",
    "    Y1= Y[1:a]\n",
    "    X1=X[0:a-1,:]\n",
    "    reg= sm.OLS(Y1,X1, missing=\"drop\").fit()\n",
    "    Y_Hat[a]= reg.predict(X[a-1,:])\n",
    "    \n",
    "OOS_SSE= np.sum((Y[M+1:]-Y_Hat[M+1:])**2)\n",
    "OOS_R2= 1-OOS_SSE/OOS_SSE_Hist\n",
    "w1= ((1/gam)*(Y_Hat/Hist_Variance)).clip(None,1.5);\n",
    "r1= Y*w1\n",
    "CE = np.mean(r1[M+1:])-gam/2*np.var(r1[M+1:],ddof=1)\n",
    "\n",
    "arr=np.array(Y_Hat).tolist()\n",
    "df1[\"Y_m_pred\"]=arr\n",
    "\n",
    "print(\"OOS R^2 = %6.3f\"%(100.0*OOS_R2))\n",
    "print('Difference in Certainty Equivalence = %7.4f'%(100*(CE-CE_Hist)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-f006bbe60668>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"median_var\"]= df1.median(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOS R^2 = -0.592\n",
      "Difference in Certainty Equivalence = -0.0165\n"
     ]
    }
   ],
   "source": [
    "# repeat same process for median\n",
    "df[\"median_var\"]= df1.median(axis=1)\n",
    "\n",
    "Y= np.asarray(df[dep_var])\n",
    "X= np.asarray(df['median_var'])\n",
    "Y_Hat= np.full(len(Y), np.nan)\n",
    "X= sm.add_constant(X)\n",
    "\n",
    "for a in range(M+1, len(Y)):\n",
    "    Y1= Y[1:a]\n",
    "    X1=X[0:a-1,:]\n",
    "    reg= sm.OLS(Y1,X1, missing=\"drop\").fit()\n",
    "    Y_Hat[a]= reg.predict(X[a-1,:])\n",
    "    \n",
    "OOS_SSE= np.sum((Y[M+1:]-Y_Hat[M+1:])**2)\n",
    "OOS_R2= 1-OOS_SSE/OOS_SSE_Hist\n",
    "w1= ((1/gam)*(Y_Hat/Hist_Variance)).clip(None,1.5);\n",
    "r1= Y*w1\n",
    "CE = np.mean(r1[M+1:])-gam/2*np.var(r1[M+1:],ddof=1)\n",
    "\n",
    "arr=np.array(Y_Hat).tolist()\n",
    "df1[\"Y_m_pred\"]=arr\n",
    "\n",
    "print(\"OOS R^2 = %6.3f\"%(100.0*OOS_R2))\n",
    "print('Difference in Certainty Equivalence = %7.4f'%(100*(CE-CE_Hist)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpretation: values for mean are not a good predictor as the numbers are high and away from 0- however they are a better predictor compared to regression\n",
    "#for median- it is a good predictor, the out of sample r^2 and CEV is close to 0 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
